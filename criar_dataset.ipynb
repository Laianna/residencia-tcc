{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ranking\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUNAS = (\"descricao_1\", \"ean_1\", \"titulo_1\", \"url_1\",\t\"titulo_cb_1\", \"loja_1\",\n",
    "           \"descricao_2\", \"ean_2\", \"titulo_2\", \"url_2\",\t\"titulo_cb_2\", \"loja_2\",\n",
    "           \"match\")\n",
    "#NUM_AMOSTRAS = 280\n",
    "DIRETORIO = \"Dados/Datasets/\"\n",
    "\n",
    "#lista_nomes = [\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\"]\n",
    "lista_nomes = [\"fogoes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"Dados/Produtos Processados/pp_{lista_nomes[0]}.csv\")\n",
    "df['ean'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "produto = lista_nomes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montando os Pares e os Não Pares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets que vou montar:\n",
    "\n",
    "    1. Hard negative dataset\n",
    "        Não matches são feitos de acordo com o algoritmo de rankeamento. Pega o não-match mais próximo\n",
    "    2. Aleatório\n",
    "        Não matches são feitos aleatóriamente dentro da categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_dicionario(descricao_1, ean_1, titulo_1, url_1, titulo_cb_1, loja_1,\n",
    "                     descricao_2, ean_2, titulo_2, url_2, titulo_cb_2, loja_2,\n",
    "                     match):\n",
    "    \n",
    "    return {'descricao_1' : descricao_1 , 'ean_1' : ean_1, 'titulo_1' : titulo_1,\n",
    "            'url_1' : url_1, 'titulo_cb_1' : titulo_cb_1, 'loja_1' : loja_1,\n",
    "            \n",
    "            'descricao_2' : descricao_2 , 'ean_2' : ean_2, 'titulo_2' : titulo_2,\n",
    "            'url_2' : url_2 , 'titulo_cb_2' : titulo_cb_2, 'loja_2' : loja_2,\n",
    "            \n",
    "            'match' : match\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_pares(colunas, df_final_dup):\n",
    "\n",
    "    df_pares = pd.DataFrame(columns = colunas)\n",
    "    df_pares\n",
    "\n",
    "    lista_ean = []\n",
    "\n",
    "    for i in range(len(df_final_dup)):\n",
    "        \n",
    "        if df_final_dup.iloc[i]['ean'] not in lista_ean:\n",
    "            \n",
    "            lista_ean.append(df_final_dup.iloc[i]['ean'])\n",
    "            \n",
    "            indice = df_final_dup.index[df_final_dup['ean'] == df_final_dup.iloc[i]['ean']].tolist()\n",
    "            \n",
    "            for j in range(len(indice)-1):\n",
    "                \n",
    "                for k in range(j + 1, len(indice)):\n",
    "                    \n",
    "                    dicionario = criar_dicionario(descricao_1  = df_final_dup.loc[indice[j]]['descricao'] , ean_1 = df_final_dup.loc[indice[j]]['ean'],\n",
    "                                                  titulo_1 = df_final_dup.loc[indice[j]]['titulo'], url_1 = df_final_dup.loc[indice[j]]['url'],\n",
    "                                                  titulo_cb_1 = df_final_dup.loc[indice[j]]['titulo_cb'], loja_1 = df_final_dup.loc[indice[j]]['loja'],\n",
    "                                                  \n",
    "                                                  descricao_2 = df_final_dup.loc[indice[k]]['descricao'] , ean_2 = df_final_dup.loc[indice[k]]['ean'],\n",
    "                                                  titulo_2 = df_final_dup.loc[indice[k]]['titulo'], url_2 = df_final_dup.loc[indice[k]]['url'],\n",
    "                                                  titulo_cb_2 = df_final_dup.loc[indice[k]]['titulo_cb'], loja_2 = df_final_dup.loc[indice[k]]['loja'],\n",
    "                                                  \n",
    "                                                  match = 1\n",
    "                                                  )\n",
    "                \n",
    "                    df_pares = df_pares.append(dicionario, ignore_index = True)\n",
    "\n",
    "    return df_pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pares = criar_pares(COLUNAS, df)\n",
    "#df_pares[df_pares['ean_1'] != df_pares['ean_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pares.to_csv(f\"Dados/Pares/pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Não Pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pares = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aleatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_nao_pares(df_pares, qtd, colunas = COLUNAS):\n",
    "\n",
    "    n_matches = df_pares.shape[0]*qtd\n",
    "    df_nao_pares_aleatorio = pd.DataFrame(columns = colunas)\n",
    "\n",
    "    for i in range(n_matches):\n",
    "        created_match = False\n",
    "        \n",
    "        while(not created_match):\n",
    "            df_sorteado = df.sample(n = 2)\n",
    "            if(df_sorteado.iloc[0]['ean'] != df_sorteado.iloc[1]['ean']):\n",
    "                \n",
    "                dic = criar_dicionario(\n",
    "                                       df_sorteado.iloc[0]['descricao'], df_sorteado.iloc[0]['ean'], df_sorteado.iloc[0]['titulo'], df_sorteado.iloc[0]['url'], df_sorteado.iloc[0]['titulo_cb'], df_sorteado.iloc[0]['loja'],\n",
    "                                       df_sorteado.iloc[1]['descricao'], df_sorteado.iloc[1]['ean'], df_sorteado.iloc[1]['titulo'], df_sorteado.iloc[1]['url'], df_sorteado.iloc[1]['titulo_cb'], df_sorteado.iloc[1]['loja'],\n",
    "                                       0\n",
    "                                      )\n",
    "                \n",
    "                df_nao_pares_aleatorio = df_nao_pares_aleatorio.append(dic, ignore_index = True)\n",
    "                created_match = True\n",
    "\n",
    "    return df_nao_pares_aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_5 = criar_nao_pares(df_pares, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_5.to_csv(f\"Dados/Não Pares/Aléatorio/5 por 1/nao_pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_1 = criar_nao_pares(df_pares, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_1.to_csv(f\"Dados/Não Pares/Aléatorio/1 por 1/nao_pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conferindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'produto = \\'celulares\\'\\np = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")\\nn = pd.read_csv(f\"Dados/Não Pares/Aléatorio/1 por 1/nao_pares_{produto}.csv\")\\n\\nprint(f\"{p.size}\\n{n.size}\")'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''produto = 'celulares'\n",
    "p = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")\n",
    "n = pd.read_csv(f\"Dados/Não Pares/Aléatorio/1 por 1/nao_pares_{produto}.csv\")\n",
    "\n",
    "print(f\"{p.size}\\n{n.size}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_lista_nao_pares_hn(df, n_matches, ean_repetido, indices_resultado, colunas = COLUNAS):\n",
    "\n",
    "    lista_final = []\n",
    "    df_nao_pares_hn = pd.DataFrame(columns = colunas)\n",
    "\n",
    "    limite = ceil(n_matches/len(ean_repetido))\n",
    "\n",
    "    for i in range(len(ean_repetido)):\n",
    "\n",
    "        lista_indice_top = []\n",
    "\n",
    "        ean = ean_repetido[i]\n",
    "\n",
    "        for indice_df in df[df['ean'] == ean].index.values: # todos os indices do dataframe onde tem o EAN repetido\n",
    "\n",
    "            lista_top_nao_rank = []\n",
    "\n",
    "            flag_encontrou = False\n",
    "            j = 0\n",
    "            cont = 0\n",
    "            while (flag_encontrou == False):\n",
    "                \n",
    "                indice_rank = indices_resultado[indice_df][j]\n",
    "\n",
    "                if df['ean'].loc[indice_df] != df['ean'].loc[indice_rank]:\n",
    "\n",
    "\n",
    "                    lista_top_nao_rank.append(indice_rank)\n",
    "\n",
    "                    cont += 1\n",
    "\n",
    "                    if cont > limite:\n",
    "                        flag_encontrou = True\n",
    "\n",
    "                j += 1\n",
    "\n",
    "            lista_indice_top.append([indice_df, lista_top_nao_rank])\n",
    "\n",
    "        lista_final.append([ean, lista_indice_top])\n",
    "\n",
    "    return lista_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_df_nao_pares_hn(df, n_matches, lista_nao_pares, colunas = COLUNAS):\n",
    "\n",
    "    df_nao_pares = pd.DataFrame(columns = colunas)\n",
    "    tam = len(np.array(lista_nao_pares)[:, 0])\n",
    "\n",
    "    contador = 0\n",
    "    voltas = 0\n",
    "    while contador < n_matches:\n",
    "\n",
    "        for i in range(tam):\n",
    "\n",
    "            if len(lista_nao_pares[i][1]) > (voltas):\n",
    "                    j = voltas\n",
    "            else:\n",
    "                    j = 0\n",
    "\n",
    "            indice_1 = lista_nao_pares[i][1][j][0]\n",
    "            indice_2 = lista_nao_pares[i][1][j][1][0]\n",
    "\n",
    "            dicionario = criar_dicionario(\n",
    "                                            descricao_1  = df.loc[indice_1]['descricao'] , ean_1 = df.loc[indice_1]['ean'],\n",
    "                                            titulo_1 = df.loc[indice_1]['titulo'], url_1 = df.loc[indice_1]['url'],\n",
    "                                            titulo_cb_1 = df.loc[indice_1]['titulo_cb'], loja_1 = df.loc[indice_1]['loja'],\n",
    "\n",
    "                                            descricao_2 = df.loc[indice_2]['descricao'] , ean_2 = df.loc[indice_2]['ean'],\n",
    "                                            titulo_2 = df.loc[indice_2]['titulo'], url_2 = df.loc[indice_2]['url'],\n",
    "                                            titulo_cb_2 = df.loc[indice_2]['titulo_cb'], loja_2 = df.loc[indice_2]['loja'],\n",
    "\n",
    "                                            match = 0\n",
    "                                         )\n",
    "\n",
    "            df_nao_pares = df_nao_pares.append(dicionario, ignore_index = True)\n",
    "\n",
    "            del lista_nao_pares[i][1][j][1][0]\n",
    "\n",
    "            contador += 1\n",
    "\n",
    "            if contador == n_matches:\n",
    "                break\n",
    "\n",
    "        voltas += 1\n",
    "        #print(voltas)\n",
    "\n",
    "    return df_nao_pares\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pares = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descobrindo quais EAN se repetem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vc = df['ean'].value_counts()\n",
    "#ean_repetido = vc[vc > 1].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo a pontuação do título\n",
    "#df[\"titulo_pp\"] = df[\"titulo_cb\"].apply(lambda x: ranking.remove_pontuacao(x))\n",
    "\n",
    "# calculando o tamanho máximo do título\n",
    "#tam_max = max(df.apply(lambda row: len(row[\"titulo_pp\"]), axis = 1))\n",
    "\n",
    "# calculando o BoW do título\n",
    "#cv, titulo_bow = ranking.formatar_entrada_bow(df['titulo_pp'], mf = tam_max)   # np.unique(titulo_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculando a distância entre os vetores\n",
    "#resultado = ranking.calcular_dis_2_vetores(titulo_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenando o resultado\n",
    "#indices, valores = ranking.ordenar_resultado(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_matches = df_pares.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_nao_pares = criar_lista_nao_pares_hn(df = df, n_matches = n_matches, ean_repetido = ean_repetido, indices_resultado = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares = criar_df_nao_pares_hn(df = df, n_matches = n_matches, lista_nao_pares = lista_nao_pares)\n",
    "#print(f\"Tamanho Pares:\\t\\t{df_pares.shape[0]}\\nTamanho Não Pares:\\t{df_nao_pares.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares.to_csv(f\"Dados/Não Pares/Rankeado/nao_pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montando os Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets que vou montar:\n",
    "\n",
    "    1. Hard negative dataset\n",
    "        Não matches são feitos de acordo com o algoritmo de rankeamento. Pega o não-match mais próximo\n",
    "    2. Aleatório\n",
    "        Não matches são feitos aleatóriamente dentro da categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_arquivo(df, nome):\n",
    "    df.to_csv(f\"{DIRETORIO}{nome}.csv\", index = False)\n",
    "\n",
    "\n",
    "def embaralhar(df):\n",
    "    \n",
    "    df = df.sample(frac = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def criar_dataset(lista_df, nome):\n",
    "    \n",
    "    df = pd.concat(lista_df, ignore_index = True)\n",
    "    \n",
    "    df = embaralhar(df)\n",
    "    \n",
    "    salvar_arquivo(df, nome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_nomes = [\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\"]\n",
    "lista_nomes = [\"tvs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''lista_df = []\n",
    "for nome in lista_nomes:\n",
    "    \n",
    "    df_p = pd.read_csv(f\"Dados/Pares/pares_{nome}.csv\")\n",
    "    df_np = pd.read_csv(f\"Dados/Não Pares/Rankeado/1 por 1/nao_pares_{nome}.csv\")\n",
    "    \n",
    "    lista_df.append(df_p)\n",
    "    lista_df.append(df_np)\n",
    "\n",
    "criar_dataset(lista_df, f\"Por Categoria/Hard Negative/1 por 1/hn_1_1_{nome}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''lista_df = []\n",
    "for nome in lista_nomes:\n",
    "    \n",
    "    df_p = pd.read_csv(f\"Dados/Pares/pares_{nome}.csv\")\n",
    "    df_np = pd.read_csv(f\"Dados/Não Pares/Rankeado/5 por 1/nao_pares_{nome}.csv\")\n",
    "    \n",
    "    lista_df.append(df_p)\n",
    "    lista_df.append(df_np)\n",
    "\n",
    "criar_dataset(lista_df, f\"Por Categoria/Hard Negative/5 por 1/hn_5_1_{nome}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aleatório"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''lista_df = []\n",
    "for nome in lista_nomes:\n",
    "    \n",
    "    df_p = pd.read_csv(f\"Dados/Pares/pares_{nome}.csv\")\n",
    "    df_np = pd.read_csv(f\"Dados/Não Pares/Aléatorio/1 por 1/nao_pares_{nome}.csv\")\n",
    "    \n",
    "    lista_df.append(df_p)\n",
    "    lista_df.append(df_np)\n",
    "\n",
    "criar_dataset(lista_df, f\"Por Categoria/Aleatório/1 por 1/ale_1_1_{nome}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''lista_df = []\n",
    "for nome in lista_nomes:\n",
    "    \n",
    "    df_p = pd.read_csv(f\"Dados/Pares/pares_{nome}.csv\")\n",
    "    df_np = pd.read_csv(f\"Dados/Não Pares/Aléatorio/5 por 1/nao_pares_{nome}.csv\")\n",
    "    \n",
    "    lista_df.append(df_p)\n",
    "    lista_df.append(df_np)\n",
    "\n",
    "criar_dataset(lista_df, f\"Por Categoria/Aleatório/5 por 1/ale_5_1_{nome}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando o Dataset em Treino e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70/30 por categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes = [\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\"]\n",
    "#lista_nomes = [\"tvs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_csv(tipo, tipo_abr, proporcao, nome):\n",
    "\n",
    "    df = pd.read_csv(f\"{DIRETORIO}Por Categoria/{tipo}/{proporcao} por 1/{tipo_abr}_{proporcao}_1_{nome}.csv\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def ler_csv_teste_treino(tipo, tipo_abr, proporcao, nome, teste_treino):\n",
    "\n",
    "    df = pd.read_csv(f\"{DIRETORIO}Por Categoria/{tipo}/{proporcao} por 1/{teste_treino}/{tipo_abr}_{proporcao}_1_{nome}.csv\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def salvar_csv(df, tipo, tipo_abr, proporcao, nome, teste_treino):\n",
    "\n",
    "    df.to_csv(f\"{DIRETORIO}Por Categoria/{tipo}/{proporcao} por 1/{teste_treino}/{tipo_abr}_{proporcao}_1_{nome}.csv\")\n",
    "\n",
    "\n",
    "def separar_df_70_30(df, tipo, tipo_abr, proporcao, nome, qtd = 0.7, SEED = 42):\n",
    "\n",
    "    df_treino = df.sample(frac = qtd, random_state = SEED)\n",
    "    df_teste = df.drop(df_treino.index)\n",
    "\n",
    "    print(f\"Treino: {df_treino.shape[0]} linhas\\n Teste: {df_teste.shape[0]} linhas\")\n",
    "\n",
    "    salvar_csv(df_treino, tipo, tipo_abr, proporcao, nome, \"treino\")\n",
    "    salvar_csv(df_teste, tipo, tipo_abr, proporcao, nome, \"teste\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for nome in lista_nomes:\\n\\n    for tipo, tipo_abr in [[\\'Aleatório\\', \\'ale\\'], [\\'Hard Negative\\', \\'hn\\']]:\\n\\n        for proporcao in [1, 5]:\\n\\n            df = ler_csv(tipo, tipo_abr, proporcao, nome)\\n\\n            separar_df_70_30(df, tipo, tipo_abr, proporcao, nome)\\n            \\n            print(\"\")\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for nome in lista_nomes:\n",
    "\n",
    "    for tipo, tipo_abr in [['Aleatório', 'ale'], ['Hard Negative', 'hn']]:\n",
    "\n",
    "        for proporcao in [1, 5]:\n",
    "\n",
    "            df = ler_csv(tipo, tipo_abr, proporcao, nome)\n",
    "\n",
    "            separar_df_70_30(df, tipo, tipo_abr, proporcao, nome)\n",
    "            \n",
    "            print(\"\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntandos os Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def juntar_datasets(lista_nomes, treino_teste):\n",
    "\n",
    "    for tipo, tipo_abr in [['Aleatório', 'ale'], ['Hard Negative', 'hn']]:\n",
    "\n",
    "        for proporcao in [1, 5]:\n",
    "\n",
    "            lista_df = []\n",
    "\n",
    "            for nome in lista_nomes:\n",
    "\n",
    "                df = ler_csv_teste_treino(tipo, tipo_abr, proporcao, nome, treino_teste)\n",
    "                lista_df.append(df)\n",
    "\n",
    "            criar_dataset(lista_df, f\"{tipo}/{proporcao} por 1/{tipo_abr}_{proporcao}_1_{treino_teste}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes = [\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\"]\n",
    "#lista_nomes = [\"tvs\"]\n",
    "\n",
    "juntar_datasets(lista_nomes = lista_nomes, treino_teste = \"treino\")\n",
    "juntar_datasets(lista_nomes = lista_nomes, treino_teste = \"teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo os Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ale_1 = pd.read_csv(f\"{DIRETORIO}Aleatório/1 por 1/ale_1_1_teste.csv\")\n",
    "df_ale_5 = pd.read_csv(f\"{DIRETORIO}Aleatório/5 por 1/ale_5_1_teste.csv\")\n",
    "df_hn_1 = pd.read_csv(f\"{DIRETORIO}Hard Negative/1 por 1/hn_1_1_teste.csv\")\n",
    "df_hn_5 = pd.read_csv(f\"{DIRETORIO}Hard Negative/5 por 1/hn_5_1_teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dos Datasets:\n",
      "\n",
      "\t| Hard\t| Ale\t|\n",
      "1 por 1\t| 1329\t| 1329\t|\n",
      "5 por 1\t| 3987\t| 3987\t|\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamanho dos Datasets:\\n\\n\\t| Hard\\t| Ale\\t|\\n1 por 1\\t| {df_hn_1.shape[0]}\\t| {df_ale_1.shape[0]}\\t|\\n5 por 1\\t| {df_hn_5.shape[0]}\\t| {df_ale_5.shape[0]}\\t|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ale_1 = pd.read_csv(f\"{DIRETORIO}Aleatório/1 por 1/ale_1_1_treino.csv\")\n",
    "df_ale_5 = pd.read_csv(f\"{DIRETORIO}Aleatório/5 por 1/ale_5_1_treino.csv\")\n",
    "df_hn_1 = pd.read_csv(f\"{DIRETORIO}Hard Negative/1 por 1/hn_1_1_treino.csv\")\n",
    "df_hn_5 = pd.read_csv(f\"{DIRETORIO}Hard Negative/5 por 1/hn_5_1_treino.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dos Datasets:\n",
      "\n",
      "\t| Hard\t| Ale\t|\n",
      "1 por 1\t| 3101\t| 3101\t|\n",
      "5 por 1\t| 9303\t| 9303\t|\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamanho dos Datasets:\\n\\n\\t| Hard\\t| Ale\\t|\\n1 por 1\\t| {df_hn_1.shape[0]}\\t| {df_ale_1.shape[0]}\\t|\\n5 por 1\\t| {df_hn_5.shape[0]}\\t| {df_ale_5.shape[0]}\\t|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4889b298c2b41a0f37c917b2884deb5a3a36b040cfb99d0e8c1edb9e5e6fadf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
