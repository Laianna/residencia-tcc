{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ranking\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUNAS = (\"descricao_1\", \"ean_1\", \"titulo_1\", \"url_1\",\t\"titulo_cb_1\", \"loja_1\",\n",
    "           \"descricao_2\", \"ean_2\", \"titulo_2\", \"url_2\",\t\"titulo_cb_2\", \"loja_2\",\n",
    "           \"match\")\n",
    "#NUM_AMOSTRAS = 280\n",
    "DIRETORIO = \"Dados/Datasets/\"\n",
    "\n",
    "#lista_nomes = [\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\"]\n",
    "lista_nomes = [\"celulares\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"Dados/Produtos Processados/pp_{lista_nomes[0]}.csv\")\n",
    "df['ean'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "produto = lista_nomes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montando os Pares e os Não Pares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets que vou montar:\n",
    "\n",
    "    1. Hard negative dataset\n",
    "        Não matches são feitos de acordo com o algoritmo de rankeamento. Pega o não-match mais próximo\n",
    "    2. Aleatório\n",
    "        Não matches são feitos aleatóriamente dentro da categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_dicionario(descricao_1, ean_1, titulo_1, url_1, titulo_cb_1, loja_1,\n",
    "                     descricao_2, ean_2, titulo_2, url_2, titulo_cb_2, loja_2,\n",
    "                     match):\n",
    "    \n",
    "    return {'descricao_1' : descricao_1 , 'ean_1' : ean_1, 'titulo_1' : titulo_1,\n",
    "            'url_1' : url_1, 'titulo_cb_1' : titulo_cb_1, 'loja_1' : loja_1,\n",
    "            \n",
    "            'descricao_2' : descricao_2 , 'ean_2' : ean_2, 'titulo_2' : titulo_2,\n",
    "            'url_2' : url_2 , 'titulo_cb_2' : titulo_cb_2, 'loja_2' : loja_2,\n",
    "            \n",
    "            'match' : match\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_pares(colunas, df_final_dup):\n",
    "\n",
    "    df_pares = pd.DataFrame(columns = colunas)\n",
    "    df_pares\n",
    "\n",
    "    lista_ean = []\n",
    "\n",
    "    for i in range(len(df_final_dup)):\n",
    "        \n",
    "        if df_final_dup.iloc[i]['ean'] not in lista_ean:\n",
    "            \n",
    "            lista_ean.append(df_final_dup.iloc[i]['ean'])\n",
    "            \n",
    "            indice = df_final_dup.index[df_final_dup['ean'] == df_final_dup.iloc[i]['ean']].tolist()\n",
    "            \n",
    "            for j in range(len(indice)-1):\n",
    "                \n",
    "                for k in range(j + 1, len(indice)):\n",
    "                    \n",
    "                    dicionario = criar_dicionario(descricao_1  = df_final_dup.loc[indice[j]]['descricao'] , ean_1 = df_final_dup.loc[indice[j]]['ean'],\n",
    "                                                  titulo_1 = df_final_dup.loc[indice[j]]['titulo'], url_1 = df_final_dup.loc[indice[j]]['url'],\n",
    "                                                  titulo_cb_1 = df_final_dup.loc[indice[j]]['titulo_cb'], loja_1 = df_final_dup.loc[indice[j]]['loja'],\n",
    "                                                  \n",
    "                                                  descricao_2 = df_final_dup.loc[indice[k]]['descricao'] , ean_2 = df_final_dup.loc[indice[k]]['ean'],\n",
    "                                                  titulo_2 = df_final_dup.loc[indice[k]]['titulo'], url_2 = df_final_dup.loc[indice[k]]['url'],\n",
    "                                                  titulo_cb_2 = df_final_dup.loc[indice[k]]['titulo_cb'], loja_2 = df_final_dup.loc[indice[k]]['loja'],\n",
    "                                                  \n",
    "                                                  match = 1\n",
    "                                                  )\n",
    "                \n",
    "                    df_pares = df_pares.append(dicionario, ignore_index = True)\n",
    "\n",
    "    return df_pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pares = criar_pares(COLUNAS, df)\n",
    "#df_pares[df_pares['ean_1'] != df_pares['ean_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pares.to_csv(f\"Dados/Pares/pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Não Pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pares = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aleatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_nao_pares(df_pares, qtd, colunas = COLUNAS):\n",
    "\n",
    "    n_matches = df_pares.shape[0]*qtd\n",
    "    df_nao_pares_aleatorio = pd.DataFrame(columns = colunas)\n",
    "\n",
    "    for i in range(n_matches):\n",
    "        created_match = False\n",
    "        \n",
    "        while(not created_match):\n",
    "            df_sorteado = df.sample(n = 2)\n",
    "            if(df_sorteado.iloc[0]['ean'] != df_sorteado.iloc[1]['ean']):\n",
    "                \n",
    "                dic = criar_dicionario(df_sorteado.iloc[0]['descricao'], df_sorteado.iloc[0]['ean'], df_sorteado.iloc[0]['titulo'], df_sorteado.iloc[0]['url'], df_sorteado.iloc[0]['titulo_cb'], df_sorteado.iloc[0]['loja'],\n",
    "                                    df_sorteado.iloc[1]['descricao'], df_sorteado.iloc[1]['ean'], df_sorteado.iloc[1]['titulo'], df_sorteado.iloc[1]['url'], df_sorteado.iloc[1]['titulo_cb'], df_sorteado.iloc[1]['loja'],\n",
    "                                    0)\n",
    "                \n",
    "                df_nao_pares_aleatorio = df_nao_pares_aleatorio.append(dic, ignore_index = True)\n",
    "                created_match = True\n",
    "\n",
    "    return df_nao_pares_aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_5 = criar_nao_pares(df_pares, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_5.to_csv(f\"Dados/Não Pares/Aléatorio/5 por 1/nao_pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_1 = criar_nao_pares(df_pares, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_1.to_csv(f\"Dados/Não Pares/Aléatorio/1 por 1/nao_pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conferindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'produto = \\'celulares\\'\\np = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")\\nn = pd.read_csv(f\"Dados/Não Pares/Aléatorio/1 por 1/nao_pares_{produto}.csv\")\\n\\nprint(f\"{p.size}\\n{n.size}\")'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''produto = 'celulares'\n",
    "p = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")\n",
    "n = pd.read_csv(f\"Dados/Não Pares/Aléatorio/1 por 1/nao_pares_{produto}.csv\")\n",
    "\n",
    "print(f\"{p.size}\\n{n.size}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pares = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descobrindo quais EAN se repetem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = df['ean'].value_counts()\n",
    "ean_repetido = vc[vc > 1].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo a pontuação do título\n",
    "df[\"titulo_pp\"] = df[\"titulo_cb\"].apply(lambda x: ranking.remove_pontuacao(x))\n",
    "\n",
    "# calculando o tamanho máximo do título\n",
    "tam_max = max(df.apply(lambda row: len(row[\"titulo_pp\"]), axis = 1))\n",
    "\n",
    "# calculando o BoW do título\n",
    "cv, titulo_bow = ranking.formatar_entrada_bow(df['titulo_pp'], mf = tam_max)\n",
    "#np.unique(titulo_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\llvs2\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:699: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "# calculando a distância entre os vetores\n",
    "resultado = ranking.calcular_dis_2_vetores(titulo_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14780/836354671.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "    a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenando o resultado\n",
    "indices, valores = ranking.ordenar_resultado(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_nao_pares_hn(df, n_matches, ean_repetido, indices_resultado, colunas = COLUNAS):\n",
    "\n",
    "    df_nao_pares_hn = pd.DataFrame(columns = colunas)\n",
    "\n",
    "    if n_matches > len(ean_repetido):\n",
    "        print(\"Mais não matches necessários que quantidade de EANS duplicados disponíveis\")\n",
    "\n",
    "    for i in range(n_matches):      \n",
    "\n",
    "        ean = ean_repetido[i]\n",
    "        indice_df = df[df['ean'] == ean].head(1).index.values[0] # me da o 1º indice do dataframe onde tem o EAN repetido\n",
    "\n",
    "\n",
    "        flag_encontrou = False\n",
    "        j = 0\n",
    "        while (flag_encontrou == False):\n",
    "            \n",
    "            indice_rank = indices_resultado[indice_df][j]\n",
    "\n",
    "            if df['ean'].loc[indice_rank] != df['ean'].loc[indice_df]:\n",
    "\n",
    "                dicionario = criar_dicionario(\n",
    "                                              descricao_1 = df.loc[indice_df]['descricao'] , ean_1 = df.loc[indice_df]['ean'],\n",
    "                                              titulo_1 =    df.loc[indice_df]['titulo'], url_1 = df.loc[indice_df]['url'],\n",
    "                                              titulo_cb_1 = df.loc[indice_df]['titulo_cb'], loja_1 = df.loc[indice_df]['loja'],\n",
    "                                                  \n",
    "                                              descricao_2 = df.loc[indice_rank]['descricao'] , ean_2 = df.loc[indice_rank]['ean'],\n",
    "                                              titulo_2 =    df.loc[indice_rank]['titulo'], url_2 = df.loc[indice_rank]['url'],\n",
    "                                              titulo_cb_2 = df.loc[indice_rank]['titulo_cb'], loja_2 = df.loc[indice_rank]['loja'],\n",
    "                                                  \n",
    "                                              match = 0\n",
    "                                             )\n",
    "                \n",
    "                df_nao_pares_hn = df_nao_pares_hn.append(dicionario, ignore_index = True)\n",
    "\n",
    "                flag_encontrou = True\n",
    "\n",
    "            j += 1\n",
    "\n",
    "\n",
    "    return df_nao_pares_hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ean_repetido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pares.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = criar_nao_pares_hn(df = df, n_matches = df_pares.shape[0], ean_repetido = ean_repetido, indices_resultado = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_nao_pares_hn(df, n_matches, ean_repetido, indices_resultado, colunas = COLUNAS):\n",
    "\n",
    "    lista_3 = []\n",
    "    df_nao_pares_hn = pd.DataFrame(columns = colunas)\n",
    "\n",
    "    limite = ceil(n_matches/len(ean_repetido))\n",
    "\n",
    "    for i in range(len(ean_repetido)):\n",
    "\n",
    "        lista_1 = []\n",
    "        lista_2 = []\n",
    "\n",
    "        ean = ean_repetido[i]\n",
    "        indice_df = df[df['ean'] == ean].head(1).index.values[0] # me da o 1º indice do dataframe onde tem o EAN repetido\n",
    "        lista_1.append(indice_df)\n",
    "\n",
    "        flag_encontrou = False\n",
    "        j = 0\n",
    "        cont = 0\n",
    "        while (flag_encontrou == False):\n",
    "            \n",
    "            indice_rank = indices_resultado[indice_df][j]\n",
    "\n",
    "            if df['ean'].loc[indice_df] != df['ean'].loc[indice_rank]:\n",
    "\n",
    "\n",
    "                lista_2.append(indice_rank)\n",
    "\n",
    "                cont += 1\n",
    "\n",
    "                if cont > limite:\n",
    "                    flag_encontrou = True\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        lista_3.append([lista_1, lista_2])\n",
    "\n",
    "    return lista_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_3 = criar_nao_pares_hn(df = df, n_matches = df_pares.shape[0], ean_repetido = ean_repetido, indices_resultado = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_3[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ean', 'titulo_pp']].iloc[761]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ean', 'titulo_pp']].iloc[1432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ean                                                                                                                     7892509122580\n",
       "titulo    Smartphone Samsung Galaxy S22 Ultra 512GB 5G com caneta S pen - Preto, Câmera Tripla 108MP + Selfie 40MP, ram 8GB, Tela 6.8\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ean', 'titulo']].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ean                                            7895183061763\n",
       "titulo    Cômoda 4 Gavetas Flora 4130 Ébano Touch - DEMÓBILE\n",
       "Name: 1432, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ean', 'titulo']].loc[1432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1432, 1733, 2073, 1348, 1290, 7, 5]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0][0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 0.9500000000000001, 0.9500000000000001]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores[0][0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(len(resultado[0])):\n",
    "\n",
    "    if resultado[0][r] == 1.0:\n",
    "\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montando os Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets que vou montar:\n",
    "\n",
    "    1. Hard negative dataset\n",
    "        Não matches são feitos de acordo com o algoritmo de rankeamento. Pega o não-match mais próximo\n",
    "    2. Aleatório\n",
    "        Não matches são feitos aleatóriamente dentro da categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_arquivo(df, nome):\n",
    "    df.to_csv(f\"{DIRETORIO}{nome}.csv\", index = False)\n",
    "\n",
    "\n",
    "def embaralhar(df):\n",
    "    \n",
    "    df = df.sample(frac = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def criar_dataset(lista_df, nome):\n",
    "    \n",
    "    df = pd.concat(lista_df, ignore_index = True)\n",
    "    \n",
    "    df = embaralhar(df)\n",
    "    \n",
    "    salvar_arquivo(df, nome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_df = []\n",
    "for nome in lista_nomes:\n",
    "    \n",
    "    df = pd.read_csv(f\"Dados/Total Pares/total_pares_{nome}.csv\")\n",
    "    lista_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_dataset(lista_df, \"hn_desbalanceado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_df = []\n",
    "for nome in lista_nomes:\n",
    "    \n",
    "    df_p = pd.read_csv(f\"Dados/Pares/pares_{nome}.csv\").sample(n = NUM_AMOSTRAS)\n",
    "    df_np = pd.read_csv(f\"Dados/Não Pares/nao_pares_{nome}.csv\").sample(n = NUM_AMOSTRAS*5)\n",
    "    \n",
    "    lista_df.append(df_p)\n",
    "    lista_df.append(df_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_dataset(lista_df, \"hn_balanceado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aleatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_df = []\n",
    "for nome in lista_nomes:\n",
    "    \n",
    "    df = pd.read_csv(f\"Dados/Pares/pares_{nome}.csv\")\n",
    "    lista_df.append(df)\n",
    "    \n",
    "df = pd.read_csv(f\"Dados/Não Pares/nao_pares_pp_desbalanceado.csv\")\n",
    "lista_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criar_dataset(lista_df, \"sn_desbalanceado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hnb = pd.read_csv(f\"Dados/Datasets/hn_balanceado.csv\")\n",
    "df_hnd = pd.read_csv(f\"Dados/Datasets/hn_desbalanceado.csv\")\n",
    "df_snb = pd.read_csv(f\"Dados/Datasets/sn_balanceado.csv\")\n",
    "df_snd = pd.read_csv(f\"Dados/Datasets/sn_desbalanceado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tamanho dos Datasets:\\n\\n\\t\\t| Hard\\t| Soft\\t|\\nBalanceado\\t| {df_hnb.shape[0]}\\t| {df_snb.shape[0]}\\t|\\nDesbalanceado\\t| {df_hnd.shape[0]}\\t| {df_snd.shape[0]}\\t|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4889b298c2b41a0f37c917b2884deb5a3a36b040cfb99d0e8c1edb9e5e6fadf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
