{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ranking\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUNAS = (\n",
    "           \"descricao_1\", \"ean_1\", \"titulo_1\", \"url_1\",\t\"titulo_cb_1\", \"loja_1\",\n",
    "           \"descricao_2\", \"ean_2\", \"titulo_2\", \"url_2\",\t\"titulo_cb_2\", \"loja_2\",\n",
    "           \"categoria\", \"match\"\n",
    "          )\n",
    "#NUM_AMOSTRAS = 280\n",
    "DIRETORIO = \"Dados/Datasets/\"\n",
    "\n",
    "#lista_nomes = [\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\"]\n",
    "lista_nomes = [\"fogoes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pp = pd.read_csv(f\"Dados/Produtos Processados/pp_{lista_nomes[0]}.csv\")\n",
    "df_pp['ean'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "produto = lista_nomes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montando os Pares e os Não Pares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets que vou montar:\n",
    "\n",
    "    1. Hard negative dataset\n",
    "        Não matches são feitos de acordo com o algoritmo de rankeamento. Pega o não-match mais próximo\n",
    "    2. Aleatório\n",
    "        Não matches são feitos aleatóriamente dentro da categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_dicionario(descricao_1, ean_1, titulo_1, url_1, titulo_cb_1, loja_1,\n",
    "                     descricao_2, ean_2, titulo_2, url_2, titulo_cb_2, loja_2,\n",
    "                     categoria, match):\n",
    "    \n",
    "    return {\n",
    "            'descricao_1' : descricao_1 , 'ean_1' : ean_1, 'titulo_1' : titulo_1,\n",
    "            'url_1' : url_1, 'titulo_cb_1' : titulo_cb_1, 'loja_1' : loja_1,\n",
    "            \n",
    "            'descricao_2' : descricao_2 , 'ean_2' : ean_2, 'titulo_2' : titulo_2,\n",
    "            'url_2' : url_2 , 'titulo_cb_2' : titulo_cb_2, 'loja_2' : loja_2,\n",
    "\n",
    "            'categoria' : categoria, 'match' : match\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_pares(colunas, df_pp, produto):\n",
    "\n",
    "    df_pares = pd.DataFrame(columns = colunas)\n",
    "    df_pares\n",
    "\n",
    "    lista_ean = []\n",
    "\n",
    "    for i in range(len(df_pp)):\n",
    "        \n",
    "        if df_pp.iloc[i]['ean'] not in lista_ean:\n",
    "            \n",
    "            lista_ean.append(df_pp.iloc[i]['ean'])\n",
    "            \n",
    "            indice = df_pp.index[df_pp['ean'] == df_pp.iloc[i]['ean']].tolist()\n",
    "            \n",
    "            for j in range(len(indice)-1):\n",
    "                \n",
    "                for k in range(j + 1, len(indice)):\n",
    "                    \n",
    "                    dicionario = criar_dicionario(descricao_1  = df_pp.loc[indice[j]]['descricao'] , ean_1 = df_pp.loc[indice[j]]['ean'],\n",
    "                                                  titulo_1 = df_pp.loc[indice[j]]['titulo'], url_1 = df_pp.loc[indice[j]]['url'],\n",
    "                                                  titulo_cb_1 = df_pp.loc[indice[j]]['titulo_cb'], loja_1 = df_pp.loc[indice[j]]['loja'],\n",
    "                                                  \n",
    "                                                  descricao_2 = df_pp.loc[indice[k]]['descricao'] , ean_2 = df_pp.loc[indice[k]]['ean'],\n",
    "                                                  titulo_2 = df_pp.loc[indice[k]]['titulo'], url_2 = df_pp.loc[indice[k]]['url'],\n",
    "                                                  titulo_cb_2 = df_pp.loc[indice[k]]['titulo_cb'], loja_2 = df_pp.loc[indice[k]]['loja'],\n",
    "\n",
    "                                                  categoria = produto, match = 1\n",
    "                                                 )\n",
    "                \n",
    "                    df_pares = df_pares.append(dicionario, ignore_index = True)\n",
    "\n",
    "    return df_pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pares = criar_pares(COLUNAS, df_pp, produto)\n",
    "#df_pares[df_pares['ean_1'] != df_pares['ean_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pares.to_csv(f\"Dados/Pares/pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Não Pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pares = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")\n",
    "df_pares_tam = df_pares.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aleatório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_nao_pares(df_pp, df_pares_tam, qtd, produto, colunas = COLUNAS):\n",
    "\n",
    "    n_matches = df_pares_tam*qtd\n",
    "    df_nao_pares_aleatorio = pd.DataFrame(columns = colunas)\n",
    "\n",
    "    for i in range(n_matches):\n",
    "        flag_criou_match = False\n",
    "        \n",
    "        while(not flag_criou_match):\n",
    "\n",
    "            df_sorteado = df_pp.sample(n = 2)\n",
    "\n",
    "            if(df_sorteado.iloc[0]['ean'] != df_sorteado.iloc[1]['ean']):\n",
    "                \n",
    "                dicionario = criar_dicionario(\n",
    "                                              descricao_1  = df_sorteado.iloc[0]['descricao'] , ean_1 = df_sorteado.iloc[0]['ean'],\n",
    "                                              titulo_1 = df_sorteado.iloc[0]['titulo'], url_1 = df_sorteado.iloc[0]['url'],\n",
    "                                              titulo_cb_1 = df_sorteado.iloc[0]['titulo_cb'], loja_1 = df_sorteado.iloc[0]['loja'],\n",
    "                                                  \n",
    "                                              descricao_2 = df_sorteado.iloc[1]['descricao'] , ean_2 = df_sorteado.iloc[1]['ean'],\n",
    "                                              titulo_2 = df_sorteado.iloc[1]['titulo'], url_2 = df_sorteado.iloc[1]['url'],\n",
    "                                              titulo_cb_2 = df_sorteado.iloc[1]['titulo_cb'], loja_2 = df_sorteado.iloc[1]['loja'],\n",
    "                                              \n",
    "                                              categoria = produto, match = 0\n",
    "                                             )\n",
    "                \n",
    "                df_nao_pares_aleatorio = df_nao_pares_aleatorio.append(dicionario, ignore_index = True)\n",
    "\n",
    "                flag_criou_match = True\n",
    "\n",
    "    return df_nao_pares_aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_5 = criar_nao_pares(df_pp, df_pares_tam, 5, produto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_5.to_csv(f\"Dados/Não Pares/Aleatório/5 por 1/nao_pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_1 = criar_nao_pares(df_pp, df_pares_tam, 1, produto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nao_pares_aleatorio_1.to_csv(f\"Dados/Não Pares/Aleatório/1 por 1/nao_pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conferindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'produto = \\'fogoes\\'\\np = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")\\nn = pd.read_csv(f\"Dados/Não Pares/Aléatorio/1 por 1/nao_pares_{produto}.csv\")\\n\\nprint(f\"{p.size}\\n{n.size}\")'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''produto = 'fogoes'\n",
    "p = pd.read_csv(f\"Dados/Pares/pares_{produto}.csv\")\n",
    "n = pd.read_csv(f\"Dados/Não Pares/Aléatorio/1 por 1/nao_pares_{produto}.csv\")\n",
    "\n",
    "print(f\"{p.size}\\n{n.size}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_lista_nao_pares_hn(df, n_matches, ean_repetido, indices_resultado, colunas = COLUNAS):\n",
    "\n",
    "    lista_final = []\n",
    "    df_nao_pares_hn = pd.DataFrame(columns = colunas)\n",
    "\n",
    "    limite = ceil(n_matches/len(ean_repetido))\n",
    "\n",
    "    for i in range(len(ean_repetido)):\n",
    "\n",
    "        lista_indice_top = []\n",
    "\n",
    "        ean = ean_repetido[i]\n",
    "\n",
    "        for indice_df in df[df['ean'] == ean].index.values: # todos os indices do dataframe onde tem o EAN repetido\n",
    "\n",
    "            lista_top_nao_rank = []\n",
    "\n",
    "            flag_encontrou = False\n",
    "            j = 0\n",
    "            cont = 0\n",
    "            while (flag_encontrou == False):\n",
    "                \n",
    "                indice_rank = indices_resultado[indice_df][j]\n",
    "\n",
    "                if df['ean'].loc[indice_df] != df['ean'].loc[indice_rank]:\n",
    "\n",
    "\n",
    "                    lista_top_nao_rank.append(indice_rank)\n",
    "\n",
    "                    cont += 1\n",
    "\n",
    "                    if cont > limite:\n",
    "                        flag_encontrou = True\n",
    "\n",
    "                j += 1\n",
    "\n",
    "            lista_indice_top.append([indice_df, lista_top_nao_rank])\n",
    "\n",
    "        lista_final.append([ean, lista_indice_top])\n",
    "\n",
    "    return lista_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_df_nao_pares_hn(df, n_matches, lista_nao_pares, produto, colunas = COLUNAS):\n",
    "\n",
    "    df_nao_pares = pd.DataFrame(columns = colunas)\n",
    "    tam = len(np.array(lista_nao_pares)[:, 0])\n",
    "\n",
    "    contador = 0\n",
    "    voltas = 0\n",
    "    while contador < n_matches:\n",
    "\n",
    "        for i in range(tam):\n",
    "\n",
    "            if len(lista_nao_pares[i][1]) > (voltas):\n",
    "                    j = voltas\n",
    "            else:\n",
    "                    j = 0\n",
    "\n",
    "            indice_1 = lista_nao_pares[i][1][j][0]\n",
    "            indice_2 = lista_nao_pares[i][1][j][1][0]\n",
    "\n",
    "            dicionario = criar_dicionario(\n",
    "                                            descricao_1  = df.loc[indice_1]['descricao'] , ean_1 = df.loc[indice_1]['ean'],\n",
    "                                            titulo_1 = df.loc[indice_1]['titulo'], url_1 = df.loc[indice_1]['url'],\n",
    "                                            titulo_cb_1 = df.loc[indice_1]['titulo_cb'], loja_1 = df.loc[indice_1]['loja'],\n",
    "\n",
    "                                            descricao_2 = df.loc[indice_2]['descricao'] , ean_2 = df.loc[indice_2]['ean'],\n",
    "                                            titulo_2 = df.loc[indice_2]['titulo'], url_2 = df.loc[indice_2]['url'],\n",
    "                                            titulo_cb_2 = df.loc[indice_2]['titulo_cb'], loja_2 = df.loc[indice_2]['loja'],\n",
    "\n",
    "                                            categoria = produto, match = 0\n",
    "                                         )\n",
    "\n",
    "            df_nao_pares = df_nao_pares.append(dicionario, ignore_index = True)\n",
    "\n",
    "            del lista_nao_pares[i][1][j][1][0]\n",
    "\n",
    "            contador += 1\n",
    "\n",
    "            if contador == n_matches:\n",
    "                break\n",
    "\n",
    "        voltas += 1\n",
    "        #print(voltas)\n",
    "\n",
    "    return df_nao_pares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_nao_pares_hn(df_pp, df_pares_tam, qtd, ean_repetido, indices, produto, flag_salvar = False):\n",
    "\n",
    "    n_matches = df_pares_tam*qtd\n",
    "\n",
    "    lista_nao_pares = criar_lista_nao_pares_hn(df = df_pp, n_matches = n_matches, ean_repetido = ean_repetido, indices_resultado = indices)\n",
    "\n",
    "    df_nao_pares = criar_df_nao_pares_hn(df = df_pp, n_matches = n_matches, lista_nao_pares = lista_nao_pares, produto = produto)\n",
    "    print(f\"Tamanho Pares:\\t\\t{df_pares.shape[0]}\\nTamanho Não Pares:\\t{df_nao_pares.shape[0]}\")\n",
    "\n",
    "    if flag_salvar == True:\n",
    "        df_nao_pares.to_csv(f\"Dados/Não Pares/Rankeado/{qtd} por 1/nao_pares_{produto}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descobrindo quais EAN se repetem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vc = df_pp['ean'].value_counts()\n",
    "#ean_repetido = vc[vc > 1].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_pp[\"titulo_sp\"] = df_pp[\"titulo_cb\"].apply(lambda x: ranking.remove_pontuacao(x))\\ndf_pp[\"titulo_sa\"] = df_pp[\"titulo_sp\"].apply(lambda x: ranking.tirar_acento(x))\\n\\nresults = set()\\ndf_pp[\\'titulo_sa\\'].str.lower().str.split().apply(results.update)\\ntam_max = len(results)\\n\\n# calculando o BoW do título\\ncv, titulo_bow = ranking.formatar_entrada_bow(df_pp[\\'titulo_sa\\'], mf = tam_max)   # np.unique(titulo_bow)'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removendo a pontuação do título\n",
    "'''df_pp[\"titulo_sp\"] = df_pp[\"titulo_cb\"].apply(lambda x: ranking.remove_pontuacao(x))\n",
    "df_pp[\"titulo_sa\"] = df_pp[\"titulo_sp\"].apply(lambda x: ranking.tirar_acento(x))\n",
    "\n",
    "results = set()\n",
    "df_pp['titulo_sa'].str.lower().str.split().apply(results.update)\n",
    "tam_max = len(results)\n",
    "\n",
    "# calculando o BoW do título\n",
    "cv, titulo_bow = ranking.formatar_entrada_bow(df_pp['titulo_sa'], mf = tam_max)   # np.unique(titulo_bow)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bow = pd.DataFrame( titulo_bow , columns = cv.get_feature_names() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculando a distância entre os vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultado = ranking.calcular_dis_2_vetores(titulo_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ordenando o resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices, valores = ranking.ordenar_resultado(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_nao_pares_hn(df_pp, df_pares_tam, 5, ean_repetido, indices, produto, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_nao_pares_hn(df_pp, df_pares_tam, 1, ean_repetido, indices, produto, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montando os Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets que vou montar:\n",
    "\n",
    "    1. Hard negative dataset\n",
    "        Não matches são feitos de acordo com o algoritmo de rankeamento. Pega o não-match mais próximo de acordo com a distância do cosseno\n",
    "    2. Aleatório\n",
    "        Não matches são feitos aleatóriamente dentro da categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_salvar_arquivo = (\n",
    "                        ['Rankeado', 'Hard Negative', 'hn'],\n",
    "                        ['Aleatório', 'Aleatório', 'ale']\n",
    "                       )\n",
    "\n",
    "\n",
    "def salvar_arquivo(df, nome):\n",
    "    df.to_csv(f\"{DIRETORIO}{nome}.csv\", index = False)\n",
    "\n",
    "\n",
    "def embaralhar(df):\n",
    "    \n",
    "    df = df.sample(frac = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def criar_dataset(lista_nomes, tipo, qtd):\n",
    "\n",
    "    lista_df = []\n",
    "    for nome in lista_nomes:\n",
    "        \n",
    "        df_p = pd.read_csv(f\"Dados/Pares/pares_{nome}.csv\")\n",
    "        df_np = pd.read_csv(f\"Dados/Não Pares/{tipo[0]}/{qtd} por 1/nao_pares_{nome}.csv\")\n",
    "        \n",
    "        lista_df.append(df_p)\n",
    "        lista_df.append(df_np)\n",
    "        \n",
    "        df = pd.concat(lista_df, ignore_index = True)        \n",
    "        df = embaralhar(df)\n",
    "        \n",
    "        salvar_arquivo(df, f\"Por Categoria/{tipo[1]}/{qtd} por 1/{tipo[2]}_{qtd}_1_{nome}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_nomes = [\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\"]\n",
    "lista_nomes = [\"fogoes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar_dataset(lista_nomes, lista_salvar_arquivo[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar_dataset(lista_nomes, lista_salvar_arquivo[0], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aleatório"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar_dataset(lista_nomes, lista_salvar_arquivo[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar_dataset(lista_nomes, lista_salvar_arquivo[1], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando o Dataset em Treino e Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70/30 por categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes = [\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_csv(tipo, tipo_abr, proporcao, nome):\n",
    "\n",
    "    df = pd.read_csv(f\"{DIRETORIO}Por Categoria/{tipo}/{proporcao} por 1/{tipo_abr}_{proporcao}_1_{nome}.csv\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def ler_csv_teste_treino(tipo, tipo_abr, proporcao, nome, teste_treino):\n",
    "\n",
    "    df = pd.read_csv(f\"{DIRETORIO}Por Categoria/{tipo}/{proporcao} por 1/{teste_treino}/{tipo_abr}_{proporcao}_1_{nome}.csv\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def salvar_csv(df, tipo, tipo_abr, proporcao, nome, teste_treino):\n",
    "\n",
    "    df.to_csv(f\"{DIRETORIO}Por Categoria/{tipo}/{proporcao} por 1/{teste_treino}/{tipo_abr}_{proporcao}_1_{nome}.csv\", index = False)\n",
    "\n",
    "\n",
    "def separar_df_70_30(df, tipo, tipo_abr, proporcao, nome, qtd = 0.7, SEED = 42):\n",
    "\n",
    "    df_treino = df.sample(frac = qtd, random_state = SEED)\n",
    "    df_teste = df.drop(df_treino.index)\n",
    "\n",
    "    print(f\"Treino: {df_treino.shape[0]} linhas\\n Teste: {df_teste.shape[0]} linhas\")\n",
    "\n",
    "    salvar_csv(df_treino, tipo, tipo_abr, proporcao, nome, \"treino\")\n",
    "    salvar_csv(df_teste, tipo, tipo_abr, proporcao, nome, \"teste\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for nome in lista_nomes:\\n\\n    for tipo, tipo_abr in [[\\'Aleatório\\', \\'ale\\'], [\\'Hard Negative\\', \\'hn\\']]:\\n\\n        for proporcao in [1, 5]:\\n\\n            df = ler_csv(tipo, tipo_abr, proporcao, nome)\\n\\n            separar_df_70_30(df, tipo, tipo_abr, proporcao, nome)\\n            \\n            print(\"\")'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for nome in lista_nomes:\n",
    "\n",
    "    for tipo, tipo_abr in [['Aleatório', 'ale'], ['Hard Negative', 'hn']]:\n",
    "\n",
    "        for proporcao in [1, 5]:\n",
    "\n",
    "            df = ler_csv(tipo, tipo_abr, proporcao, nome)\n",
    "\n",
    "            separar_df_70_30(df, tipo, tipo_abr, proporcao, nome)\n",
    "            \n",
    "            print(\"\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando o Dataset de Treino em Treino e Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_csv_t_v(tipo, tipo_abr, proporcao, nome):\n",
    "\n",
    "    df = pd.read_csv(f\"{DIRETORIO}Por Categoria/{tipo}/{proporcao} por 1/treino/{tipo_abr}_{proporcao}_1_{nome}.csv\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def ler_csv_teste_val(tipo, tipo_abr, proporcao, nome, teste_val):\n",
    "\n",
    "    df = pd.read_csv(f\"{DIRETORIO}Por Categoria/{tipo}/{proporcao} por 1/treino/{teste_val}/{tipo_abr}_{proporcao}_1_{nome}.csv\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def salvar_csv_t_v(df, tipo, tipo_abr, proporcao, nome, teste_val):\n",
    "\n",
    "    df.to_csv(f\"{DIRETORIO}Por Categoria/{tipo}/{proporcao} por 1/treino/{teste_val}/{tipo_abr}_{proporcao}_1_{nome}.csv\", index = False)\n",
    "\n",
    "\n",
    "def separar_treino_validacao(df, tipo, tipo_abr, proporcao, nome, qtd = 0.7, SEED = 42):\n",
    "\n",
    "    df_treino = df.sample(frac = qtd, random_state = SEED)\n",
    "    df_val = df.drop(df_treino.index)\n",
    "\n",
    "    print(f\"Treino: {df_treino.shape[0]} linhas\\n Val: {df_val.shape[0]} linhas\")\n",
    "\n",
    "    salvar_csv_t_v(df_treino, tipo, tipo_abr, proporcao, nome, \"treino\")\n",
    "    salvar_csv_t_v(df_val, tipo, tipo_abr, proporcao, nome, \"validação\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: 292 linhas\n",
      " Val: 125 linhas\n",
      "\n",
      "Treino: 876 linhas\n",
      " Val: 376 linhas\n",
      "\n",
      "Treino: 292 linhas\n",
      " Val: 125 linhas\n",
      "\n",
      "Treino: 876 linhas\n",
      " Val: 376 linhas\n",
      "\n",
      "Treino: 391 linhas\n",
      " Val: 168 linhas\n",
      "\n",
      "Treino: 1173 linhas\n",
      " Val: 503 linhas\n",
      "\n",
      "Treino: 391 linhas\n",
      " Val: 168 linhas\n",
      "\n",
      "Treino: 1173 linhas\n",
      " Val: 503 linhas\n",
      "\n",
      "Treino: 274 linhas\n",
      " Val: 118 linhas\n",
      "\n",
      "Treino: 823 linhas\n",
      " Val: 353 linhas\n",
      "\n",
      "Treino: 274 linhas\n",
      " Val: 118 linhas\n",
      "\n",
      "Treino: 823 linhas\n",
      " Val: 353 linhas\n",
      "\n",
      "Treino: 892 linhas\n",
      " Val: 383 linhas\n",
      "\n",
      "Treino: 2678 linhas\n",
      " Val: 1148 linhas\n",
      "\n",
      "Treino: 892 linhas\n",
      " Val: 383 linhas\n",
      "\n",
      "Treino: 2678 linhas\n",
      " Val: 1148 linhas\n",
      "\n",
      "Treino: 321 linhas\n",
      " Val: 137 linhas\n",
      "\n",
      "Treino: 961 linhas\n",
      " Val: 412 linhas\n",
      "\n",
      "Treino: 321 linhas\n",
      " Val: 137 linhas\n",
      "\n",
      "Treino: 961 linhas\n",
      " Val: 412 linhas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''for nome in lista_nomes:\n",
    "\n",
    "    for tipo, tipo_abr in [['Aleatório', 'ale'], ['Hard Negative', 'hn']]:\n",
    "\n",
    "        for proporcao in [1, 5]:\n",
    "\n",
    "            df = ler_csv_t_v(tipo, tipo_abr, proporcao, nome)\n",
    "\n",
    "            separar_treino_validacao(df, tipo, tipo_abr, proporcao, nome)\n",
    "            \n",
    "            print(\"\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntandos os Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino - Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def juntar_datasets(lista_nomes, treino_teste):\n",
    "\n",
    "    for tipo, tipo_abr in [['Aleatório', 'ale'], ['Hard Negative', 'hn']]:\n",
    "\n",
    "        for proporcao in [1, 5]:\n",
    "\n",
    "            lista_df = []\n",
    "\n",
    "            for nome in lista_nomes:\n",
    "\n",
    "                df = ler_csv_teste_treino(tipo, tipo_abr, proporcao, nome, treino_teste)\n",
    "                lista_df.append(df)\n",
    "\n",
    "            df = pd.concat(lista_df, ignore_index = True)                \n",
    "            df = embaralhar(df)\n",
    "            \n",
    "            salvar_arquivo(df, f\"Treino-Teste/{treino_teste}/{tipo_abr}_{proporcao}_1_{treino_teste}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes = [\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\"]\n",
    "#lista_nomes = [\"tvs\"]\n",
    "\n",
    "juntar_datasets(lista_nomes = lista_nomes, treino_teste = \"treino\")\n",
    "juntar_datasets(lista_nomes = lista_nomes, treino_teste = \"teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino - Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def juntar_datasets_t_v(lista_nomes, treino_val):\n",
    "\n",
    "    for tipo, tipo_abr in [['Aleatório', 'ale'], ['Hard Negative', 'hn']]:\n",
    "\n",
    "        for proporcao in [1, 5]:\n",
    "\n",
    "            lista_df = []\n",
    "\n",
    "            for nome in lista_nomes:\n",
    "\n",
    "                df = ler_csv_teste_val(tipo, tipo_abr, proporcao, nome, treino_val)\n",
    "                lista_df.append(df)\n",
    "\n",
    "            df = pd.concat(lista_df, ignore_index = True)                \n",
    "            df = embaralhar(df)\n",
    "            \n",
    "            salvar_arquivo(df, f\"Treino-Validação/{treino_val}/{tipo_abr}_{proporcao}_1_{treino_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes = [\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\"]\n",
    "#lista_nomes = [\"tvs\"]\n",
    "\n",
    "juntar_datasets_t_v(lista_nomes = lista_nomes, treino_val = \"treino\")\n",
    "juntar_datasets_t_v(lista_nomes = lista_nomes, treino_val = \"validação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo os Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste - Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ale_1 = pd.read_csv(f\"{DIRETORIO}Teste/ale_1_1_teste.csv\")\n",
    "df_ale_5 = pd.read_csv(f\"{DIRETORIO}Teste/ale_5_1_teste.csv\")\n",
    "df_hn_1 = pd.read_csv(f\"{DIRETORIO}Teste/hn_1_1_teste.csv\")\n",
    "df_hn_5 = pd.read_csv(f\"{DIRETORIO}Teste/hn_5_1_teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dos Datasets:\n",
      "\n",
      "\t| Hard\t| Ale\t|\n",
      "1 por 1\t| 1329\t| 1329\t|\n",
      "5 por 1\t| 3987\t| 3987\t|\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamanho dos Datasets:\\n\\n\\t| Hard\\t| Ale\\t|\\n1 por 1\\t| {df_hn_1.shape[0]}\\t| {df_ale_1.shape[0]}\\t|\\n5 por 1\\t| {df_hn_5.shape[0]}\\t| {df_ale_5.shape[0]}\\t|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ale_1 = pd.read_csv(f\"{DIRETORIO}Treino/ale_1_1_treino.csv\")\n",
    "df_ale_5 = pd.read_csv(f\"{DIRETORIO}Treino/ale_5_1_treino.csv\")\n",
    "df_hn_1 = pd.read_csv(f\"{DIRETORIO}Treino/hn_1_1_treino.csv\")\n",
    "df_hn_5 = pd.read_csv(f\"{DIRETORIO}Treino/hn_5_1_treino.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dos Datasets:\n",
      "\n",
      "\t| Hard\t| Ale\t|\n",
      "1 por 1\t| 3101\t| 3101\t|\n",
      "5 por 1\t| 9303\t| 9303\t|\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamanho dos Datasets:\\n\\n\\t| Hard\\t| Ale\\t|\\n1 por 1\\t| {df_hn_1.shape[0]}\\t| {df_ale_1.shape[0]}\\t|\\n5 por 1\\t| {df_hn_5.shape[0]}\\t| {df_ale_5.shape[0]}\\t|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste - Validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ale_1 = pd.read_csv(f\"{DIRETORIO}Treino-Validação/Treino/ale_1_1_treino.csv\")\n",
    "df_ale_5 = pd.read_csv(f\"{DIRETORIO}Treino-Validação/Treino/ale_5_1_treino.csv\")\n",
    "df_hn_1 = pd.read_csv(f\"{DIRETORIO}Treino-Validação/Treino/hn_1_1_treino.csv\")\n",
    "df_hn_5 = pd.read_csv(f\"{DIRETORIO}Treino-Validação/Treino/hn_5_1_treino.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dos Datasets:\n",
      "\n",
      "\t| Hard\t| Ale\t|\n",
      "1 por 1\t| 2170\t| 2170\t|\n",
      "5 por 1\t| 6511\t| 6511\t|\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamanho dos Datasets:\\n\\n\\t| Hard\\t| Ale\\t|\\n1 por 1\\t| {df_hn_1.shape[0]}\\t| {df_ale_1.shape[0]}\\t|\\n5 por 1\\t| {df_hn_5.shape[0]}\\t| {df_ale_5.shape[0]}\\t|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ale_1 = pd.read_csv(f\"{DIRETORIO}Treino-Validação/Validação/ale_1_1_validação.csv\")\n",
    "df_ale_5 = pd.read_csv(f\"{DIRETORIO}Treino-Validação/Validação/ale_5_1_validação.csv\")\n",
    "df_hn_1 = pd.read_csv(f\"{DIRETORIO}Treino-Validação/Validação/hn_1_1_validação.csv\")\n",
    "df_hn_5 = pd.read_csv(f\"{DIRETORIO}Treino-Validação/Validação/hn_5_1_validação.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho dos Datasets:\n",
      "\n",
      "\t| Hard\t| Ale\t|\n",
      "1 por 1\t| 931\t| 931\t|\n",
      "5 por 1\t| 2792\t| 2792\t|\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamanho dos Datasets:\\n\\n\\t| Hard\\t| Ale\\t|\\n1 por 1\\t| {df_hn_1.shape[0]}\\t| {df_ale_1.shape[0]}\\t|\\n5 por 1\\t| {df_hn_5.shape[0]}\\t| {df_ale_5.shape[0]}\\t|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4889b298c2b41a0f37c917b2884deb5a3a36b040cfb99d0e8c1edb9e5e6fadf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
