{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = ['ale_1_1', 'ale_5_1', 'hn_1_1', 'hn_5_1']\n",
    "\n",
    "lista_df_treino = []\n",
    "lista_df_teste = []\n",
    "for arquivo in arquivos:\n",
    "\n",
    "    df_treino = pd.read_csv(f\"Dados/Datasets/Treino/{arquivo}_treino.csv\", dtype = {'ean_1': str, 'ean_2': str})\n",
    "    df_teste = pd.read_csv(f\"Dados/Datasets/Teste/{arquivo}_teste.csv\", dtype = {'ean_1': str, 'ean_2': str})\n",
    "    lista_df_treino.append(df_treino)\n",
    "    lista_df_teste.append(df_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_df_resultado(report, modelo, nome_dataset, tempo_exec):\n",
    "    \n",
    "    df_resultado = pd.DataFrame(report).transpose()\n",
    "    df_resultado['modelo'] = modelo\n",
    "    df_resultado['dataset'] = nome_dataset\n",
    "    df_resultado['tempo'] = tempo_exec\n",
    "\n",
    "    df_resultado.to_csv(f'Dados/Resultados/{modelo}/{nome_dataset}_resultado.csv', index = True)\n",
    "    \n",
    "    return df_resultado\n",
    "\n",
    "\n",
    "def salvar_modelo(modelo, dataset, metodo):\n",
    "    \n",
    "    nome_arquivo = f\"Dados/Modelos/modelo_{dataset}_{metodo}\"\n",
    "    pickle.dump(modelo, open(nome_arquivo, 'wb'))\n",
    "\n",
    "\n",
    "def carregar_modelo(nome, metodo):\n",
    "    \n",
    "    modelo = pickle.load(open(f\"Dados/Modelos/modelo_{nome}_{metodo}\", 'rb'))\n",
    "    return modelo\n",
    "\n",
    "\n",
    "def salvar_modelo_bert(modelo, dataset, metodo):\n",
    "    \n",
    "    nome_arquivo = f\"Dados/Modelos/{metodo}/{dataset}/\"\n",
    "    modelo.save_pretrained(nome_arquivo)\n",
    "\n",
    "\n",
    "def carregar_modelo_bert(nome, dataset, metodo):\n",
    "    \n",
    "    from transformers import TFAutoModel\n",
    "    \n",
    "    modelo = TFAutoModel.from_pretrained(f\"Dados/Modelos/{metodo}/{dataset}/\")\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_usem(titulo_1, titulo_2):\n",
    "    \n",
    "    # model initialization\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "    \n",
    "    # Calculando embeddings\n",
    "    embedding_1 = embed(titulo_1)\n",
    "    embedding_2 = embed(titulo_2)\n",
    "\n",
    "    similaridade = []\n",
    "    for i in range(len(embedding_1)):\n",
    "        # Calculando a matriz de similaridade. Quanto maior o score maior a similaridade.\n",
    "        similaridade.append(np.inner(embedding_1[i], embedding_2[i]))\n",
    "\n",
    "    return similaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder Multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_usem = True\n",
    "if flag_usem == True:\n",
    "\n",
    "    tam = 10\n",
    "    for nome, df_treino, df_teste in zip(arquivos, lista_df_treino, lista_df_teste):\n",
    "        \n",
    "        X_teste_1 = df_teste[\"titulo_1\"]\n",
    "        X_teste_2 = df_teste[\"titulo_2\"]\n",
    "        y_teste = df_teste[\"match\"].to_list()\n",
    "\n",
    "        inicio_tempo = time.time()\n",
    "        #similaridade = pipeline_usem(X_teste_1[:tam], X_teste_2[:tam])\n",
    "        similaridade = pipeline_usem(X_teste_1, X_teste_2)\n",
    "        final_tempo = time.time()\n",
    "        tempo = final_tempo - inicio_tempo\n",
    "\n",
    "        y_pred = [1 if num >= 0.5 else 0 for num in similaridade]\n",
    "\n",
    "        #report = classification_report(y_teste[:tam], y_pred, output_dict = True)\n",
    "        report = classification_report(y_teste, y_pred, output_dict = True)\n",
    "        df_resultado = pd.DataFrame(report).transpose()\n",
    "        df_resultado['modelo'] = nome\n",
    "        df_resultado['tempo'] = tempo\n",
    "\n",
    "        df_resultado.to_csv(f'Dados/Resultados/USEM/{nome}_resultado.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4889b298c2b41a0f37c917b2884deb5a3a36b040cfb99d0e8c1edb9e5e6fadf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
