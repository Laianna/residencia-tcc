{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ranking\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"] = \"UNCOMPRESSED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "VAR_USEM = (0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquivos = ['ale_1_1', 'ale_5_1', 'hn_1_1', 'hn_5_1']\n",
    "#arquivos = ['ale_1_1']\n",
    "#arquivos = ['ale_5_1']\n",
    "arquivos = ['hn_1_1']\n",
    "#arquivos = ['hn_5_1']\n",
    "\n",
    "lista_df_treino = []\n",
    "lista_df_teste = []\n",
    "for arquivo in arquivos:\n",
    "\n",
    "    df_treino = pd.read_csv(f\"Dados/Datasets/Treino/{arquivo}_treino.csv\", dtype = {'ean_1': str, 'ean_2': str})\n",
    "    df_teste = pd.read_csv(f\"Dados/Datasets/Teste/{arquivo}_teste.csv\", dtype = {'ean_1': str, 'ean_2': str})\n",
    "    lista_df_treino.append(df_treino)\n",
    "    lista_df_teste.append(df_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_y_pred(limite, similaridade):\n",
    "\n",
    "    y_pred = [1 if num >= limite else 0 for num in similaridade]\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def salvar_df_resultado(report, modelo, nome_dataset, tempo_exec):\n",
    "    \n",
    "    df_resultado = pd.DataFrame(report).transpose()\n",
    "    df_resultado['modelo'] = modelo\n",
    "    df_resultado['dataset'] = nome_dataset\n",
    "    df_resultado['tempo'] = tempo_exec\n",
    "\n",
    "    df_resultado.to_csv(f'Dados/Resultados/{modelo}/{nome_dataset}_resultado.csv', index = True)\n",
    "    \n",
    "    return df_resultado\n",
    "\n",
    "\n",
    "def montar_df_resultado(y_teste, y_pred, df_teste, nome):\n",
    "    df_y = pd.DataFrame(\n",
    "                        list(zip(\n",
    "                                 y_teste, y_pred,\n",
    "                                 df_teste[\"categoria\"].to_list(),\n",
    "                                 df_teste[\"titulo_1\"].to_list(),\n",
    "                                 df_teste[\"titulo_2\"].to_list()\n",
    "                                )\n",
    "                       ), columns = ['match', 'pred', 'categoria', 'titulo_1', 'titulo_2'])\n",
    "\n",
    "    return df_y\n",
    "\n",
    "\n",
    "def salvar_sim_dis(y_teste, similaridade, df_teste, nome, dis_sim = \"Distância\"):\n",
    "\n",
    "    df_y = montar_df_resultado(y_teste, similaridade, df_teste, nome)\n",
    "    df_y.to_csv(f'Dados/Resultados/USEM/{dis_sim}/{nome}_similaridade.csv', index = False)\n",
    "\n",
    "\n",
    "def salvar_y_pred(y_teste, y_pred, df_teste, nome, limite, dis_sim = \"Distância\"):\n",
    "\n",
    "    df_y = montar_df_resultado(y_teste, y_pred, df_teste, nome)\n",
    "    df_y.to_csv(f'Dados/Resultados/USEM/{dis_sim}/USEM_{limite}/Resultado/{nome}_y.csv', index = False)\n",
    "\n",
    "\n",
    "def salvar_relatorio(y_teste, y_pred, nome, tempo, limite, dis_sim = \"Distância\"):\n",
    "\n",
    "    relatorio = classification_report(y_teste, y_pred, output_dict = True)\n",
    "    df_relatorio = pd.DataFrame(relatorio).transpose()\n",
    "    df_relatorio['modelo'] = nome\n",
    "    df_relatorio['tempo'] = tempo\n",
    "\n",
    "    df_relatorio.to_csv(f'Dados/Resultados/USEM/{dis_sim}/USEM_{limite}/Relatório/{nome}_relatório.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_usem(titulo_1, titulo_2):\n",
    "    \n",
    "    # model initialization\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "    \n",
    "    # Calculando embeddings\n",
    "    embedding_1 = embed(titulo_1)\n",
    "    embedding_2 = embed(titulo_2)\n",
    "\n",
    "    similaridade = []\n",
    "    distancia = []\n",
    "    for i in range(len(embedding_1)):\n",
    "        # Calculando a matriz de similaridade. Quanto maior o score maior a similaridade.\n",
    "        similaridade.append(np.inner(embedding_1[i], embedding_2[i]))\n",
    "        distancia.append(ranking.calcular_dis_cos(embedding_1[i], embedding_2[i]))\n",
    "\n",
    "    return similaridade, distancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder Multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_usem = True\n",
    "if flag_usem == True:\n",
    "\n",
    "    #tam = 10\n",
    "    for nome, df_teste in zip(arquivos, lista_df_teste):\n",
    "        \n",
    "        X_teste_1 = df_teste[\"titulo_1\"]\n",
    "        X_teste_2 = df_teste[\"titulo_2\"]\n",
    "        y_teste = df_teste[\"match\"].to_list()\n",
    "\n",
    "        inicio_tempo = time.time()\n",
    "        #y_teste = y_teste[:tam]\n",
    "        #similaridade, distancia = pipeline_usem(X_teste_1[:tam], X_teste_2[:tam])\n",
    "        similaridade, distancia = pipeline_usem(X_teste_1, X_teste_2)\n",
    "        final_tempo = time.time()\n",
    "        tempo = final_tempo - inicio_tempo\n",
    "\n",
    "        salvar_sim_dis(y_teste, similaridade, df_teste, nome, \"Similaridade\")\n",
    "        salvar_sim_dis(y_teste, distancia, df_teste, nome)\n",
    "\n",
    "        for limite in VAR_USEM:\n",
    "\n",
    "            y_pred_sim = calcular_y_pred(limite, similaridade)\n",
    "\n",
    "            salvar_y_pred( y_teste, y_pred_sim, df_teste, nome, ranking.remove_pontuacao(str(limite)), \"Similaridade\" )\n",
    "            salvar_relatorio( y_teste, y_pred_sim, nome, tempo, ranking.remove_pontuacao(str(limite)), \"Similaridade\" )\n",
    "\n",
    "            y_pred_dis = calcular_y_pred(limite, distancia)\n",
    "\n",
    "            salvar_y_pred( y_teste, y_pred_dis, df_teste, nome, ranking.remove_pontuacao(str(limite)) )\n",
    "            salvar_relatorio( y_teste, y_pred_dis, nome, tempo, ranking.remove_pontuacao(str(limite)) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4889b298c2b41a0f37c917b2884deb5a3a36b040cfb99d0e8c1edb9e5e6fadf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
