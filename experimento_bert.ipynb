{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import funcoes_bert as fb\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo os Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquivos = ['ale_1_1']\n",
    "arquivos = ['ale_5_1']\n",
    "#arquivos = ['hn_1_1']\n",
    "#arquivos = ['hn_5_1']\n",
    "\n",
    "lista_df_treino = []\n",
    "lista_df_val = []\n",
    "lista_df_teste = []\n",
    "for arquivo in arquivos:\n",
    "\n",
    "    df = pd.read_csv(f\"Dados/Datasets/Treino-Validação/Treino/{arquivo}_treino.csv\", dtype = {'ean_1': str, 'ean_2': str})\n",
    "    lista_df_treino.append(df)\n",
    "\n",
    "    df = pd.read_csv(f\"Dados/Datasets/Treino-Validação/Validação/{arquivo}_validação.csv\", dtype = {'ean_1': str, 'ean_2': str})\n",
    "    lista_df_val.append(df)\n",
    "\n",
    "    df = pd.read_csv(f\"Dados/Datasets/Teste/{arquivo}_teste.csv\", dtype = {'ean_1': str, 'ean_2': str})\n",
    "    lista_df_teste.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_df_val[0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Tamanho do Dataset de Treino 1 por 1:\\n\\n\\t| Ale\\t| Hard\\t|\\n1 por 1\\t| {lista_df_treino[0].shape[0]}\\t| {lista_df_treino[2].shape[0]}\\t|\\n5 por 1\\t| {lista_df_treino[1].shape[0]}\\t| {lista_df_treino[3].shape[0]}\\t|\")\n",
    "#print(f\"\\nTamanho do Dataset de Validação 1 por 1:\\n\\n\\t| Ale\\t| Hard\\t|\\n1 por 1\\t| {lista_df_val[0].shape[0]}\\t| {lista_df_val[2].shape[0]}\\t|\\n5 por 1\\t| {lista_df_val[1].shape[0]}\\t| {lista_df_val[3].shape[0]}\\t|\")\n",
    "#print(f\"\\nTamanho do Dataset de Teste 1 por 1:\\n\\n\\t| Ale\\t| Hard\\t|\\n1 por 1\\t| {lista_df_teste[0].shape[0]}\\t| {lista_df_teste[2].shape[0]}\\t|\\n5 por 1\\t| {lista_df_teste[1].shape[0]}\\t| {lista_df_teste[3].shape[0]}\\t|\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_modelo_bert(modelo, nome):\n",
    "    \n",
    "    nome_arquivo = f\"Dados/Modelos/BERT/{nome}/\"\n",
    "    modelo.save_pretrained(nome_arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando o BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6511/6511 [==============================] - 1704s 259ms/step - loss: 0.1170 - accuracy: 0.9590 - val_loss: 0.0569 - val_accuracy: 0.9778\n",
      "Epoch 2/3\n",
      "6511/6511 [==============================] - 1691s 260ms/step - loss: 0.0602 - accuracy: 0.9791 - val_loss: 0.0752 - val_accuracy: 0.9756\n",
      "Epoch 3/3\n",
      "6511/6511 [==============================] - 1691s 260ms/step - loss: 0.0541 - accuracy: 0.9840 - val_loss: 0.0777 - val_accuracy: 0.9749\n"
     ]
    }
   ],
   "source": [
    "lista_df_resultado = []\n",
    "tam = 20\n",
    "for nome, df_treino, df_val, df_teste in zip(arquivos, lista_df_treino, lista_df_val, lista_df_teste):\n",
    "    \n",
    "    X_treino = df_treino[[\"titulo_1\", \"titulo_2\"]]\n",
    "    X_val = df_val[[\"titulo_1\", \"titulo_2\"]]\n",
    "    X_teste = df_teste[[\"titulo_1\", \"titulo_2\"]]\n",
    "\n",
    "    y_treino = df_treino[\"match\"].to_list()\n",
    "    y_val = df_val[\"match\"].to_list()\n",
    "    y_teste = df_teste[\"match\"].to_list()\n",
    "\n",
    "    inicio_tempo = time.time()\n",
    "\n",
    "    #y_teste = y_teste[:tam]\n",
    "    #(modelo, historico, y_pred) = fb.pipeline_bert(X_treino[:tam], y_treino[:tam], X_val[:tam], y_val[:tam], X_teste[:tam], y_teste)\n",
    "    (modelo, historico, y_pred) = fb.pipeline_bert(X_treino, y_treino, X_val, y_val, X_teste, y_teste)\n",
    "    \n",
    "    final_tempo = time.time()\n",
    "\n",
    "    tempo = final_tempo - inicio_tempo\n",
    "\n",
    "    pd.DataFrame.from_dict(historico.history).to_csv(f'Dados/Resultados/BERT/Histórico/{nome}_historico.csv', index = False)\n",
    "\n",
    "    relatorio = classification_report(y_teste, y_pred, output_dict = True)\n",
    "    df_resultado = pd.DataFrame(relatorio).transpose()\n",
    "    df_resultado['modelo'] = nome\n",
    "    df_resultado['tempo'] = tempo\n",
    "\n",
    "    df_resultado.to_csv(f'Dados/Resultados/BERT/Relatório/{nome}_relatório.csv', index = True)\n",
    "\n",
    "    df_y = pd.DataFrame(\n",
    "                        list(zip(\n",
    "                                 y_teste, y_pred,\n",
    "                                 df_teste[\"categoria\"].to_list(),\n",
    "                                 df_teste[\"titulo_1\"].to_list(),\n",
    "                                 df_teste[\"titulo_2\"].to_list()\n",
    "                                )\n",
    "                       ), columns = ['match', 'pred', 'categoria', 'titulo_1', 'titulo_2'])\n",
    "    df_y.to_csv(f'Dados/Resultados/BERT/Resultado/{nome}_y.csv', index = False)\n",
    "\n",
    "    salvar_modelo_bert(modelo, nome)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_teste, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_df_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntando os Relatórios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando e Concatenando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lê os arquivos com os resultados e depois concatena em um único dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = ['ale_1_1', 'ale_5_1', 'hn_1_1', 'hn_5_1']\n",
    "lista_df_resultados = []\n",
    "for nome in arquivos:\n",
    "\n",
    "    df = pd.read_csv(f\"Dados/Resultados/BERT/Relatório/{nome}_relatório.csv\", dtype = {'ean_1': str, 'ean_2': str})\n",
    "    lista_df_resultados.append(df)\n",
    "\n",
    "df_resultados = pd.concat(lista_df_resultados, ignore_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>modelo</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.995298</td>\n",
       "      <td>0.959215</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>662.000000</td>\n",
       "      <td>ale_1_1</td>\n",
       "      <td>1811.781599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.960926</td>\n",
       "      <td>0.995502</td>\n",
       "      <td>0.977909</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>ale_1_1</td>\n",
       "      <td>1811.781599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.977427</td>\n",
       "      <td>0.977427</td>\n",
       "      <td>0.977427</td>\n",
       "      <td>0.977427</td>\n",
       "      <td>ale_1_1</td>\n",
       "      <td>1811.781599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.978112</td>\n",
       "      <td>0.977358</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>ale_1_1</td>\n",
       "      <td>1811.781599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.977427</td>\n",
       "      <td>0.977418</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>ale_1_1</td>\n",
       "      <td>1811.781599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.973887</td>\n",
       "      <td>0.993943</td>\n",
       "      <td>0.983813</td>\n",
       "      <td>3302.000000</td>\n",
       "      <td>ale_5_1</td>\n",
       "      <td>5393.620386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.967585</td>\n",
       "      <td>0.871533</td>\n",
       "      <td>0.917051</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>ale_5_1</td>\n",
       "      <td>5393.620386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.972912</td>\n",
       "      <td>0.972912</td>\n",
       "      <td>0.972912</td>\n",
       "      <td>0.972912</td>\n",
       "      <td>ale_5_1</td>\n",
       "      <td>5393.620386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.970736</td>\n",
       "      <td>0.932738</td>\n",
       "      <td>0.950432</td>\n",
       "      <td>3987.000000</td>\n",
       "      <td>ale_5_1</td>\n",
       "      <td>5393.620386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.972804</td>\n",
       "      <td>0.972912</td>\n",
       "      <td>0.972343</td>\n",
       "      <td>3987.000000</td>\n",
       "      <td>ale_5_1</td>\n",
       "      <td>5393.620386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.677223</td>\n",
       "      <td>0.855385</td>\n",
       "      <td>0.755948</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>hn_1_1</td>\n",
       "      <td>1822.995474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.609720</td>\n",
       "      <td>0.697557</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>hn_1_1</td>\n",
       "      <td>1822.995474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.729872</td>\n",
       "      <td>0.729872</td>\n",
       "      <td>0.729872</td>\n",
       "      <td>0.729872</td>\n",
       "      <td>hn_1_1</td>\n",
       "      <td>1822.995474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.746092</td>\n",
       "      <td>0.732552</td>\n",
       "      <td>0.726753</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>hn_1_1</td>\n",
       "      <td>1822.995474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.747595</td>\n",
       "      <td>0.729872</td>\n",
       "      <td>0.726116</td>\n",
       "      <td>1329.000000</td>\n",
       "      <td>hn_1_1</td>\n",
       "      <td>1822.995474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.832455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908568</td>\n",
       "      <td>3319.000000</td>\n",
       "      <td>hn_5_1</td>\n",
       "      <td>5441.051017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>hn_5_1</td>\n",
       "      <td>5441.051017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.832455</td>\n",
       "      <td>0.832455</td>\n",
       "      <td>0.832455</td>\n",
       "      <td>0.832455</td>\n",
       "      <td>hn_5_1</td>\n",
       "      <td>5441.051017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.416228</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.454284</td>\n",
       "      <td>3987.000000</td>\n",
       "      <td>hn_5_1</td>\n",
       "      <td>5441.051017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.692982</td>\n",
       "      <td>0.832455</td>\n",
       "      <td>0.756343</td>\n",
       "      <td>3987.000000</td>\n",
       "      <td>hn_5_1</td>\n",
       "      <td>5441.051017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           info  precision    recall  f1-score      support   modelo  \\\n",
       "0             0   0.995298  0.959215  0.976923   662.000000  ale_1_1   \n",
       "1             1   0.960926  0.995502  0.977909   667.000000  ale_1_1   \n",
       "2      accuracy   0.977427  0.977427  0.977427     0.977427  ale_1_1   \n",
       "3     macro avg   0.978112  0.977358  0.977416  1329.000000  ale_1_1   \n",
       "4  weighted avg   0.978047  0.977427  0.977418  1329.000000  ale_1_1   \n",
       "0             0   0.973887  0.993943  0.983813  3302.000000  ale_5_1   \n",
       "1             1   0.967585  0.871533  0.917051   685.000000  ale_5_1   \n",
       "2      accuracy   0.972912  0.972912  0.972912     0.972912  ale_5_1   \n",
       "3     macro avg   0.970736  0.932738  0.950432  3987.000000  ale_5_1   \n",
       "4  weighted avg   0.972804  0.972912  0.972343  3987.000000  ale_5_1   \n",
       "0             0   0.677223  0.855385  0.755948   650.000000   hn_1_1   \n",
       "1             1   0.814961  0.609720  0.697557   679.000000   hn_1_1   \n",
       "2      accuracy   0.729872  0.729872  0.729872     0.729872   hn_1_1   \n",
       "3     macro avg   0.746092  0.732552  0.726753  1329.000000   hn_1_1   \n",
       "4  weighted avg   0.747595  0.729872  0.726116  1329.000000   hn_1_1   \n",
       "0             0   0.832455  1.000000  0.908568  3319.000000   hn_5_1   \n",
       "1             1   0.000000  0.000000  0.000000   668.000000   hn_5_1   \n",
       "2      accuracy   0.832455  0.832455  0.832455     0.832455   hn_5_1   \n",
       "3     macro avg   0.416228  0.500000  0.454284  3987.000000   hn_5_1   \n",
       "4  weighted avg   0.692982  0.832455  0.756343  3987.000000   hn_5_1   \n",
       "\n",
       "         tempo  \n",
       "0  1811.781599  \n",
       "1  1811.781599  \n",
       "2  1811.781599  \n",
       "3  1811.781599  \n",
       "4  1811.781599  \n",
       "0  5393.620386  \n",
       "1  5393.620386  \n",
       "2  5393.620386  \n",
       "3  5393.620386  \n",
       "4  5393.620386  \n",
       "0  1822.995474  \n",
       "1  1822.995474  \n",
       "2  1822.995474  \n",
       "3  1822.995474  \n",
       "4  1822.995474  \n",
       "0  5441.051017  \n",
       "1  5441.051017  \n",
       "2  5441.051017  \n",
       "3  5441.051017  \n",
       "4  5441.051017  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados.rename(columns = {'Unnamed: 0':'info'}, inplace = True)\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando todos os resultados em um único arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.to_csv(f'Dados/Resultados/BERT/relatório_completo.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvando os Resultados por Categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_por_categoria(df_r, categoria, nome):\n",
    "\n",
    "    df_r[df_r[\"categoria\"] == categoria].to_csv(f'Dados/Resultados/BERT/Resultado/{categoria}/{nome}_y.csv', index = False)\n",
    "\n",
    "\n",
    "def relatorio_por_categoria(df_r, categoria, nome):\n",
    "\n",
    "    y_teste = df_r[df_r[\"categoria\"] == categoria]['match']\n",
    "    y_pred = df_r[df_r[\"categoria\"] == categoria]['pred']\n",
    "\n",
    "    relatorio = classification_report(y_teste, y_pred, output_dict = True)\n",
    "    df_relatorio = pd.DataFrame(relatorio).transpose()\n",
    "    df_relatorio['modelo'] = nome\n",
    "\n",
    "    df_relatorio.to_csv(f'Dados/Resultados/BERT/Relatório/{categoria}/{nome}_relatório.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e Salvamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivos = ['ale_1_1', 'ale_5_1', 'hn_1_1', 'hn_5_1']\n",
    "lista_df_resultados = []\n",
    "for nome in arquivos:\n",
    "\n",
    "    df_r = pd.read_csv(f\"Dados/Resultados/BERT/Resultado/{nome}_y.csv\")\n",
    "    lista_df_resultados.append(df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llvs2\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lista_categorias = (\"celulares\", \"notebooks\", \"geladeiras\", \"fogoes\", \"tvs\")\n",
    "for nome, df_r in zip(arquivos, lista_df_resultados):\n",
    "\n",
    "    for categoria in lista_categorias:\n",
    "\n",
    "        salvar_por_categoria(df_r, categoria, nome)\n",
    "        relatorio_por_categoria(df_r, categoria, nome)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ac14df3cc3fc15fa8da0dff0e0184c4c531d04584e8f9fc24411523fbdd16b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
